{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Autenticación de hablante en base a entrada de audio\n",
    "\n",
    "El objetivo de este notebook es la creación de una red neuronal convolucional capaz de distinguir entre parlantes en base al audio entrante y discernir si alguno de ellos es conocido en la base de datos.\n",
    "\n",
    "Para conseguir esto, primero se preprocesará el audio, tras lo cual se extraerán las MFCC features, que serán las que se utilicen para la red neuronal.\n",
    "Luego se cargará el dataset de voces conocidas usadas para entrenar la red neuronal junto con la nueva entrada de audio.\n",
    "Tras eso, se entrenará la red neuronal con los datos de entrenamiento y se evaluará con los datos de test. Si la salida coincide con uno de los usuarios almacenados en la base de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the information from data folder\n",
    "import python_speech_features as mfcc\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import Normalize\n",
    "from matplotlib import cm\n",
    "from scipy.io import wavfile\n",
    "import librosa\n",
    "import librosa.display\n",
    "from librosa.display import waveshow as waveplot\n",
    "import soundfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculates the delta of a given mfcc features array.\n",
    "\n",
    "A delta is a coefficient that helps compute and recognize speech patterns much more easily using the MFCC features.\n",
    "\n",
    "The formula used to calculate the delta is: dt=∑Nn=1n(ct+n−ct−n)2∑Nn=1n2, where ct is the current MFCC feature, n is the number of the MFCC feature and dt is the delta of the MFCC feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_delta(array):\n",
    "    rows,cols = array.shape\n",
    "    deltas = np.zeros((rows,20))\n",
    "    N = 2\n",
    "    for i in range(rows):\n",
    "        index = []\n",
    "        j = 1\n",
    "        while j <= N:\n",
    "            if i-j < 0:\n",
    "                first = 0\n",
    "            else:\n",
    "                first = i-j\n",
    "            if i+j > rows -1:\n",
    "                second = rows -1\n",
    "            else:\n",
    "                second = i+j\n",
    "            index.append((second,first))\n",
    "            j+=1\n",
    "        deltas[i] = ( array[index[0][0]]-array[index[0][1]] + (2 * (array[index[1][0]]-array[index[1][1]])) ) / 10\n",
    "    return deltas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, it preprocesses a given audio, then it extracts the MFCC features and calculates the delta of the features.\n",
    "\n",
    "Both the MFCC and the delta are returned in a single 2D array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alumno/anaconda3/envs/arqespxd/lib/python3.9/site-packages/librosa/util/decorators.py:88: UserWarning: n_fft=320 is too small for input signal of length=2\n",
      "  return f(*args, **kwargs)\n",
      "/home/alumno/anaconda3/envs/arqespxd/lib/python3.9/site-packages/librosa/util/decorators.py:88: UserWarning: Empty filters detected in mel frequency basis. Some channels will produce empty responses. Try increasing your sampling rate (and fmax) or reducing n_mels.\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1010.14343 168.35724 -9.19962 118.17884\n",
      "(3525632, 20) (3525632, 20) (3525632, 40)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-1.01014343e+03,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [-1.01014343e+03,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [-1.01014343e+03,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       ...,\n",
       "       [-9.95543335e+02,  8.24042320e+00, -3.47104120e+00, ...,\n",
       "         1.21417060e-01,  9.25187469e-02,  6.30166903e-02],\n",
       "       [-1.00965955e+03,  5.87607384e-01,  3.41254920e-01, ...,\n",
       "        -7.31834099e-02, -8.27649459e-02, -7.50745609e-02],\n",
       "       [-1.01014343e+03,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_features(audio,rate):\n",
    "    \"\"\"extract 20 dim mfcc features from an audio, performs CMS and combines \n",
    "    delta to make it 40 dim feature vector\"\"\"    \n",
    "\n",
    "    \"\"\"\n",
    "    mfcc_feature = mfcc.mfcc(audio,rate, n_mfcc=40)  \n",
    "    mfcc_feature = preprocessing.scale(mfcc_feature)\n",
    "\n",
    "    delta = calculate_delta(mfcc_feature)\n",
    "\n",
    "    combined = np.hstack((mfcc_feature,delta)) \n",
    "\n",
    "    plt.imshow(combined[:100].T, cmap = cm.jet)\n",
    "\n",
    "    print(np.min(combined), np.max(combined), np.mean(combined), np.std(combined))\"\"\"\n",
    "\n",
    "    mfc_coefficients = np.squeeze(librosa.feature.mfcc(y=audio, sr=rate, n_mfcc=20, hop_length=8000, n_fft=320))\n",
    "    deltas = librosa.feature.delta(mfc_coefficients, mode='nearest')\n",
    "\n",
    "    \n",
    "    combined = np.hstack((mfc_coefficients, deltas))\n",
    "\n",
    "    print(np.min(combined), np.max(combined), np.mean(combined), np.std(combined))\n",
    "    print(mfc_coefficients.shape, deltas.shape, combined.shape)\n",
    "    #plt.plot(combined[:100].T, cmap = cm.jet)\n",
    "\n",
    "    return combined\n",
    "\n",
    "with soundfile.SoundFile(\"audio.wav\") as audio:\n",
    "    waveform = audio.read(dtype=\"float32\")\n",
    "    sample_rate = audio.samplerate\n",
    "\n",
    "\n",
    "extract_features(waveform, sample_rate)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
